{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c499a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = (test['close'].shift(-1) > test['close']).astype(int)\n",
    "test = test[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['timestamp'], data['high'])\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Highest price during minute')\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05487453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['timestamp'], data['target'])\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('1 if high > prev minute, 0 else')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae31355",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = data['timestamp'].values.reshape(-1, 1)\n",
    "target = data['high']\n",
    "model = LinearRegression()\n",
    "model.fit(time, target)\n",
    "y_pred = model.predict(test['timestamp'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaafe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = test['high']\n",
    "mse = np.mean((y_actual - y_pred)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test['timestamp'], test['high'])\n",
    "plt.title('actual test scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test['timestamp'], y_pred)\n",
    "plt.title('predicted stock high per minute vs time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, min_samples_split = 100, random_state = 1)\n",
    "preds = [\"close\", \"high\", \"low\", \"taker_buy_base_volume\"]\n",
    "model.fit(data[preds], data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3537564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "est = model.predict(temp_test[preds])\n",
    "est = model.predict(test[preds])\n",
    "f1_macro = f1_score(test[\"target\"], est, average='macro')\n",
    "\n",
    "print(\" F1 Score:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, min_samples_split = 100, random_state = 1)\n",
    "preds = [\"high\", \"low\", \"close\"]\n",
    "model.fit(data[preds], data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = model.predict(test[preds])\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    'row_id': range(0, len(est)),\n",
    "    'predicted_target': est\n",
    "})\n",
    "prediction_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa75f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_features = ['open', 'high', 'low', 'close', 'volume', \n",
    "                'quote_asset_volume', 'number_of_trades', \n",
    "                'taker_buy_base_volume', 'taker_buy_quote_volume']\n",
    "target_column = 'target'\n",
    "X_train = data[all_features]\n",
    "y_train = data[target_column]\n",
    "X_test = test[all_features]\n",
    "y_test = test[target_column]\n",
    "\n",
    "def evaluate_feature_subsets(X_train, y_train, X_test, y_test, features):\n",
    "    best_score = 0\n",
    "    best_subset = None\n",
    "    scores_dict = {}\n",
    "    for r in range(1, len(features) + 1):\n",
    "        for subset in itertools.combinations(features, r):\n",
    "            subset = list(subset)\n",
    "            X_train_subset = X_train[subset]\n",
    "            X_test_subset = X_test[subset]\n",
    "            model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)\n",
    "            model.fit(X_train_subset, y_train)\n",
    "            y_pred = model.predict(X_test_subset)\n",
    "            score = f1_score(y_test, y_pred, average='macro')\n",
    "            scores_dict[tuple(subset)] = score\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_subset = subset\n",
    "    return best_subset, best_score, scores_dict\n",
    "best_features, best_f1, all_scores = evaluate_feature_subsets(X_train, y_train, X_test, y_test, all_features)\n",
    "\n",
    "print(\"Best subset:\", best_features)\n",
    "print(\"F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d8811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictions.csv')\n",
    "df = df.dropna(how='all')\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "print( len(test))\n",
    "print( len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
